#!/usr/bin/env ruby

URL = "https://www.coronavirus.vic.gov.au/sdp-ckan?resource_id=afb52611-6061-4a2b-9110-74c920bede77&limit=10000"
TZ = "Australia/Melbourne"
ENV["TZ"] = TZ

require 'httparty'
require 'json'
require 'nokogiri'
require 'rss'
require 'time'

class Entry
  ITEMS = %w(
    Suburb Site_title Site_streetaddress Site_postcode
    Exposure_date_dtm Exposure_time
    Advice_title Notes
    Added_date_dtm Added_time
  )
  attr_accessor *ITEMS

  attr_accessor :database_id

  def initialize(record)
    ITEMS.each do |i|
      instance_variable_set(:"@#{i}", record[i])
    end
  end

  def hash
    pod.hash
  end

  def eql?(rhs)
    pod.eql?(rhs.pod)
  end

  def pod
    Hash[ITEMS.map { |i| [i, instance_variable_get(:"@#{i}")] }]
  end

  def to_json(opts=nil)
    pod.to_json(opts)
  end
end

def merge(database, entries)
  # Add entries to end of database where not present in database.
  extant = Set.new
  database.each { |e| extant << e }
  entries.each do |e|
    if !extant.include?(e)
      database << e
    end
  end
end

def parse_time(entry)
  # XXX: screwy around DST change.  And I just bet I will still be relying
  # on this when it does change over, huh.  :|
  Time.parse(entry.Added_date_dtm + "T" + entry.Added_time)
end

Dir.chdir(__dir__)

### Fetch.

if ENV["USE_HTTP_CACHE"] == "1" && File.exists?("cache") && File.mtime("cache") > Time.now - 60 * 60
  STDERR.puts "using HTTP cache"
  data = File.read("cache")
else
  STDERR.puts "fetching new"
  data = HTTParty.get(URL).body
  File.open("cache", "w") { |f| f.write(data) }
end

data = JSON.parse(data)

exit 2 unless data["success"]


### Maintain database.

database = File.exists?("database") ? JSON.parse(File.read("database")).map { |r| Entry.new(r) } : []
merge(database, data["result"]["records"].map { |r| Entry.new(r) }.reverse)
database.each.with_index { |e, i| e.database_id = i + 1 }
File.write("database", database.to_json)


### Write RSS, HTML.

last_updated = parse_time(database[-1])


rss = RSS::Maker.make("atom") do |maker|
  maker.channel.authors.new_author do |author|
    author.name = "Asherah Connor"
    author.uri = "https://kivikakk.ee"
    author.email = "ashe@kivikakk.ee"
  end
  maker.channel.updated = last_updated
  maker.channel.about = "https://vicexposurerss.kivikakk.ee"
  maker.channel.title = "Victorian coronavirus exposure sites"

  database.reverse_each.with_index do |entry, i|
    maker.items.new_item do |item|
      item.title = "#{entry.Suburb} â€” #{entry.Site_title} (#{entry.Exposure_date_dtm})"

      summary = []
      summary << %i(Site_streetaddress Suburb Site_postcode).map { |e| entry.send(e) }.compact.join(", ")
      summary << "#{entry.Exposure_date_dtm}, #{entry.Exposure_time}"
      summary << entry.Advice_title.scan(/Tier \d/)[0]
      summary << entry.Notes
      summary << "Added #{entry.Added_date_dtm} #{entry.Added_time}"

      item.summary = summary.map { |e| e.gsub(/\.\z/, "") }.join(". ") + "."

      item.content.type = "xhtml"
      doc = Nokogiri::XML("<div></div>")
      summary.each do |line|
        doc.root.add_child(doc.create_element("p")).content = line
      end
      item.content.xml = doc.root.to_xhtml

      item.link = "https://www.coronavirus.vic.gov.au/exposure-sites##{entry.database_id}"
      item.updated = parse_time(entry)
    end
  end
end

Dir.mkdir "www" unless File.exists?("www")
File.open("www/atom.xml.new", "w") { |f| f.write(rss) }
File.rename("www/atom.xml.new", "www/atom.xml")

template = File.read("index.html.template")
doc = Nokogiri::HTML(template)

(doc/"#last-updated")[0].content = last_updated

File.open("www/index.html.new", "w") { |f| f.write(doc.to_html) }
File.rename("www/index.html.new", "www/index.html")
